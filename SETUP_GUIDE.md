# Marketing Data Collection Suite - Setup Guide

Documentation complÃ¨te pour la configuration et l'utilisation de la suite de collecte de donnÃ©es marketing (LinkedIn, Microsoft Clarity, SpyFu).

## ğŸ“‹ Table des matiÃ¨res

- [Vue d'ensemble](#vue-densemble)
- [Architecture globale](#architecture-globale)
- [PrÃ©requis techniques](#prÃ©requis-techniques)
- [Configuration Google Cloud & BigQuery](#configuration-google-cloud--bigquery)
- [Configuration LinkedIn](#configuration-linkedin)
- [Configuration Microsoft Clarity](#configuration-microsoft-clarity)
- [Configuration SpyFu](#configuration-spyfu)
- [DÃ©ploiement et exÃ©cution](#dÃ©ploiement-et-exÃ©cution)
- [SÃ©curitÃ© et bonnes pratiques](#sÃ©curitÃ©-et-bonnes-pratiques)
- [Automatisation](#automatisation)
- [Troubleshooting global](#troubleshooting-global)
- [Checklist de dÃ©ploiement](#checklist-de-dÃ©ploiement)

---

## ğŸ¯ Vue d'ensemble

Cette suite permet de collecter automatiquement des donnÃ©es marketing depuis 3 sources :

| Source | Type de donnÃ©es | FrÃ©quence recommandÃ©e |
|--------|-----------------|----------------------|
| **LinkedIn** | Campagnes publicitaires, budgets, leads | Quotidien |
| **Microsoft Clarity** | Comportement utilisateur, UX metrics | Quotidien (obligatoire) |
| **SpyFu** | SEO/PPC concurrentiel, keywords | Hebdomadaire |

**Objectif :** Centraliser toutes les donnÃ©es dans BigQuery pour analyse et reporting unifiÃ©s.

### BÃ©nÃ©fices

âœ… **Centralisation** - Toutes les donnÃ©es au mÃªme endroit
âœ… **Historisation** - Construction d'un historique long terme
âœ… **Analyse croisÃ©e** - CorrÃ©lations entre sources
âœ… **Automatisation** - Collecte sans intervention manuelle
âœ… **Backup** - Sauvegarde JSON avant upload

---

## ğŸ—ï¸ Architecture globale

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Sources de donnÃ©es                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   LinkedIn Ads  â”‚ Microsoft Clarity â”‚      SpyFu API        â”‚
â”‚   - Campaigns   â”‚   - User behavior â”‚   - SEO keywords      â”‚
â”‚   - Budgets     â”‚   - Frustration   â”‚   - PPC keywords      â”‚
â”‚   - Lead forms  â”‚   - Engagement    â”‚   - Competitors       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                   â”‚                  â”‚
         â”‚ OAuth 2.0         â”‚ API Key          â”‚ API Key
         â”‚                   â”‚                  â”‚
         v                   v                  v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Scripts Python (ce repository)                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚  linkedin/   â”‚  â”‚  microsoft_  â”‚  â”‚   spyfu/     â”‚       â”‚
â”‚  â”‚  scripts/    â”‚  â”‚  clarity/    â”‚  â”‚   scripts/   â”‚       â”‚
â”‚  â”‚              â”‚  â”‚  scripts/    â”‚  â”‚              â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚         â”‚                 â”‚                 â”‚               â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                           â”‚                                 â”‚
â”‚                  JSON Backup (data/)                        â”‚
â”‚                           â”‚                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â”‚ Service Account
                            â”‚
                            v
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   BigQuery      â”‚
                    â”‚   (Google Cloud)â”‚
                    â”‚                 â”‚
                    â”‚  - linkedin     â”‚
                    â”‚  - clarity      â”‚
                    â”‚  - spyfu        â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             v
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Visualization  â”‚
                    â”‚  - Looker       â”‚
                    â”‚  - Tableau      â”‚
                    â”‚  - Custom SQL   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ PrÃ©requis techniques

### Comptes nÃ©cessaires

| Service | Type | CoÃ»t |
|---------|------|------|
| Google Cloud Platform | Cloud provider | Gratuit pour petits volumes, puis facturation usage |
| LinkedIn Developer | Marketing API | Gratuit (nÃ©cessite Ad Account actif) |
| Microsoft Clarity | Analytics | Totalement gratuit |
| SpyFu | SEO/PPC Intelligence | Payant - selon abonnement |

### Logiciels requis

```bash
# Python 3.8+
python --version

# Pip
pip --version

# Git (pour cloner le repository)
git --version
```

---

## ğŸ“¥ Installation du code

### Ã‰tape 1 : Cloner le repository GitHub

```bash
# Cloner le repository
git clone https://github.com/clairesecehDS/marketing-data-collection.git

# Se dÃ©placer dans le dossier
cd marketing-data-collection

# Structure attendue aprÃ¨s clonage :
# marketing-data-collection/
# â”œâ”€â”€ linkedin/
# â”œâ”€â”€ microsoft_clarity/
# â”œâ”€â”€ spyfu/
# â”œâ”€â”€ SETUP_GUIDE.md
# â””â”€â”€ README.md
```

âš ï¸ **Important :** Le fichier `account-key.json` n'est PAS dans le repository (pour des raisons de sÃ©curitÃ©). Vous devrez le crÃ©er comme expliquÃ© dans la section "Configuration Google Cloud".

---

### Ã‰tape 2 : Configurer le fichier de configuration

```bash
# Copier le fichier d'exemple
cp config.example.yaml config.yaml

# Ã‰diter avec vos paramÃ¨tres
nano config.yaml  # ou vim, code, etc.
```

**Ce fichier centralise TOUTE la configuration :**
- Credentials (API keys, tokens, project IDs)
- Liste des domaines et concurrents Ã  analyser
- MÃ©triques Ã  collecter
- PÃ©riodes de collecte
- ParamÃ¨tres BigQuery
- Planification de l'automatisation

Voir section [Configuration dÃ©taillÃ©e](#-configuration-dÃ©taillÃ©e) pour remplir chaque partie.

---

### Ã‰tape 3 : Installer les dÃ©pendances Python

```bash
# CrÃ©er un environnement virtuel (recommandÃ©)
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows

# Mettre Ã  jour pip
pip install --upgrade pip

# Installer toutes les dÃ©pendances depuis requirements.txt
pip install -r requirements.txt
```

**DÃ©pendances installÃ©es :**

- `requests` - RequÃªtes HTTP vers les APIs
- `pandas` - Manipulation de donnÃ©es
- `numpy<2.0.0` - Calculs numÃ©riques (version <2.0 requise)
- `google-auth` - Authentification Google Cloud
- `google-cloud-bigquery` - Client BigQuery
- `pandas-gbq` - IntÃ©gration pandas-BigQuery
- `pyyaml` - Lecture fichiers YAML (config)

---

### Ã‰tape 4 : VÃ©rifier l'installation

```bash
# VÃ©rifier que les modules sont installÃ©s
python -c "import requests, pandas, pandas_gbq, google.auth, yaml; print('âœ“ Toutes les dÃ©pendances sont installÃ©es')"
```

---

## ğŸ”§ Configuration Google Cloud & BigQuery

### Ã‰tape 1 : CrÃ©er ou sÃ©lectionner un projet Google Cloud

1. Aller sur [Google Cloud Console](https://console.cloud.google.com/)
2. Cliquer sur le **sÃ©lecteur de projet** en haut (Ã  cÃ´tÃ© du logo Google Cloud)

**Option A : Utiliser un projet existant**
- SÃ©lectionner votre projet existant dans la liste
- **Noter le Project ID** (visible sous le nom du projet)
- Passer Ã  l'Ã‰tape 2

**Option B : CrÃ©er un nouveau projet**
1. Cliquer sur **"Nouveau projet"**
2. Renseigner :
   - **Nom du projet** : `deepscouting-marketing` (ou autre nom descriptif)
   - **Organisation** : SÃ©lectionner si applicable (optionnel)
3. Cliquer sur **"CrÃ©er"**
4. **Noter le Project ID** (ex: `clean-avatar-466709-a0`)
   - âš ï¸ Le Project ID est diffÃ©rent du nom ! Notez bien l'ID qui est gÃ©nÃ©rÃ©.

---

### Ã‰tape 2 : Activer l'API BigQuery

1. Dans la console GCP, menu latÃ©ral â†’ **"APIs & Services"** â†’ **"Library"**
2. Rechercher **"BigQuery API"**
3. Cliquer sur **"Enable"**

---

### Ã‰tape 3 : CrÃ©er un Service Account

Un Service Account permet aux scripts d'accÃ©der Ã  BigQuery de maniÃ¨re sÃ©curisÃ©e.

1. Menu latÃ©ral â†’ **"IAM & Admin"** â†’ **"Service Accounts"**
2. Cliquer sur **"Create Service Account"**
3. Renseigner :
   - **Service account name** : `marketing-data-collector`
   - **Description** : "Service account for automated data collection"
4. Cliquer sur **"Create and Continue"**

5. **Accorder les permissions** :
   - RÃ´le : **"BigQuery Data Editor"**
   - RÃ´le : **"BigQuery Job User"**
   - Cliquer sur **"Continue"**

6. Cliquer sur **"Done"**

---

### Ã‰tape 4 : GÃ©nÃ©rer une clÃ© JSON

1. Dans la liste des Service Accounts, cliquer sur le service account crÃ©Ã©
2. Onglet **"Keys"**
3. Cliquer sur **"Add Key"** â†’ **"Create new key"**
4. SÃ©lectionner **JSON**
5. Cliquer sur **"Create"**
6. Un fichier JSON se tÃ©lÃ©charge automatiquement

âš ï¸ **Important :** Ce fichier contient des credentials sensibles !

7. **Renommer le fichier** en `account-key.json`
8. **Placer le fichier** Ã  la racine du repository clonÃ© :
   ```bash
   # Si vous avez clonÃ© dans /home/user/marketing-data-collection/
   mv ~/Downloads/account-key-xxx.json /home/user/marketing-data-collection/account-key.json
   ```

9. **SÃ©curiser le fichier** :
   ```bash
   chmod 600 account-key.json
   ```

âš ï¸ **Ne jamais commiter ce fichier dans Git !** Il est dÃ©jÃ  dans le `.gitignore`.

---

### Ã‰tape 5 : CrÃ©er les datasets BigQuery

1. Menu latÃ©ral â†’ **"BigQuery"** â†’ **"Studio"** (ou "SQL Workspace" dans les anciennes versions)
2. Dans l'explorateur Ã  gauche, cliquer sur votre projet
3. Cliquer sur les **trois points** (â‹®) Ã  cÃ´tÃ© du nom du projet â†’ **"Create dataset"**

**CrÃ©er 6 datasets :**

#### Datasets LinkedIn (4 datasets)

**Dataset 1 : LinkedIn Ads Advertising**
- **Dataset ID** : `linkedin_ads_advertising`
- **Data location** : `europe-west9` (Paris) ou autre selon votre rÃ©gion

**Dataset 2 : LinkedIn Ads Library**
- **Dataset ID** : `linkedin_ads_library`
- **Data location** : `europe-west9` (Paris) ou autre selon votre rÃ©gion

**Dataset 3 : LinkedIn Lead Gen Forms**
- **Dataset ID** : `linkedin_leadgen_form`
- **Data location** : `europe-west9` (Paris) ou autre selon votre rÃ©gion

**Dataset 4 : LinkedIn Page Statistics**
- **Dataset ID** : `linkedin_page`
- **Data location** : `europe-west9` (Paris) ou autre selon votre rÃ©gion

#### Dataset 5 : Microsoft Clarity
- **Dataset ID** : `microsoft_clarity`
- **Data location** : `europe-west9` (Paris) ou autre selon votre rÃ©gion

#### Dataset 6 : SpyFu
- **Dataset ID** : `spyfu`
- **Data location** : `europe-west9` (Paris) ou autre selon votre rÃ©gion

---

### Ã‰tape 6 : CrÃ©er les tables et vues

Les fichiers SQL contiennent des Project IDs hardcodÃ©s. Le script `setup_bigquery.py` les remplace automatiquement par votre Project ID depuis `config.yaml`.

#### Option A : Script automatique (recommandÃ©) âœ¨

```bash
# ExÃ©cuter le script de setup
python setup_bigquery.py
```

Le script va :
1. âœ… Lire votre Project ID depuis `config.yaml`
2. âœ… GÃ©nÃ©rer les fichiers SQL avec le bon Project ID dans `generated_sql/`
3. âœ… Vous proposer d'exÃ©cuter automatiquement via `bq` CLI ou manuellement

Pour l'exÃ©cution automatique, il faudra au prÃ©alable vous **authentifier** avec `gcloud auth login` puis sÃ©lectionner le projet avec `gcloud config set project votre-project-id`.

Pour l'exÃ©cution automatique, il faudra au prÃ©alable vous **authentifier** avec `gcloud auth login` puis sÃ©lectionner le projet avec `gcloud config set project votre-project-id`.

**Fichiers SQL traitÃ©s (7 fichiers) :**
- `linkedin/sql/bigquery_campaign_creative_schema.sql`
- `linkedin/sql/bigquery_campaign_creative_budget_schema.sql`
- `linkedin/sql/bigquery_lead_forms_schema.sql`
- `linkedin/sql/bigquery_linkedin_page_schema.sql`
- `linkedin/sql/bigquery_ads_library_schema.sql`
- `microsoft_clarity/sql/bigquery_clarity_schema.sql`
- `spyfu/sql/bigquery_spyfu_schema.sql`

---

#### Option B : ExÃ©cution manuelle

Si vous prÃ©fÃ©rez exÃ©cuter manuellement :

**Via bq CLI :**

```bash
# 1. GÃ©nÃ©rer les fichiers SQL
python setup_bigquery.py
# Choisir option [2] pour affichage manuel

# 2. ExÃ©cuter les commandes affichÃ©es
```

**Via Console BigQuery Studio :**

1. ExÃ©cuter `python setup_bigquery.py` et choisir option [2]
2. Aller sur https://console.cloud.google.com/bigquery
3. Cliquer sur **"Studio"** â†’ **"+"** (nouvelle requÃªte)
4. Pour chaque fichier dans `generated_sql/` :
   - Copier le contenu du fichier
   - Coller dans l'Ã©diteur
   - Cliquer sur **"Run"**

âš ï¸ **Important :** Les fichiers dans `generated_sql/` utilisent votre Project ID. N'utilisez PAS directement les fichiers SQL originaux qui contiennent des IDs hardcodÃ©s !

---

### Ã‰tape 7 : Connecter Google Search Console, Google Analytics et Google Ads (NATIF)

BigQuery peut se connecter **directement** aux services Google sans code ni script ! Les donnÃ©es sont synchronisÃ©es automatiquement.

---

#### 7.1 - Google Search Console â†’ BigQuery

**Export NATIF des donnÃ©es Search Console vers BigQuery**

1. Aller sur [Google Search Console](https://search.google.com/search-console)
2. SÃ©lectionner votre propriÃ©tÃ© (site web)
3. Menu latÃ©ral â†’ **"ParamÃ¨tres"** (âš™ï¸)
4. Section **"Exportations de donnÃ©es"** â†’ Cliquer sur **"BigQuery"**
5. Cliquer sur **"Exporter vers BigQuery"**
6. Configurer :
   - **Projet Google Cloud** : SÃ©lectionner votre projet GCP
   - **Dataset** : CrÃ©er un nouveau dataset `google_search_console` ou utiliser existant
   - **FrÃ©quence** : Quotidienne (automatique)
   - **DonnÃ©es historiques** : Cocher si vous voulez les 16 derniers mois
7. Cliquer sur **"Exporter"**


**RÃ©sultat :**
- Table crÃ©Ã©e automatiquement : `searchdata_site_impression`
- Mise Ã  jour quotidienne automatique
- Colonnes : url, query, impressions, clicks, position, country, device, etc.

---

#### 7.2 - Google Analytics 4 â†’ BigQuery

**Export NATIF GA4 vers BigQuery (gratuit jusqu'Ã  1M Ã©vÃ©nements/jour)**

1. Aller dans [Google Analytics 4](https://analytics.google.com/)
2. Menu **"Admin"** (âš™ï¸ en bas Ã  gauche)
3. Colonne **"PropriÃ©tÃ©"** â†’ **"BigQuery Linking"** ou **"Lien BigQuery"**
4. Cliquer sur **"Link"** ou **"Associer"**
5. SÃ©lectionner votre projet Google Cloud
6. Configurer :
   - **Dataset location** : Choisir `EU` ou `US`
   - **Nom du dataset** : `analytics_XXXXXXXXX` (auto-gÃ©nÃ©rÃ©)
   - **FrÃ©quence d'export** :
     - âœ… **Quotidien** (Daily) - Export tous les jours Ã  ~14h
     - âœ… **Streaming** (si besoin temps rÃ©el, payant au-delÃ  de 1M Ã©vÃ©nements/jour)
   - **Inclure les donnÃ©es publicitaires** : Cocher si applicable
7. Cliquer sur **"Suivant"** â†’ **"Envoyer"**

**RÃ©sultat :**
- Tables crÃ©Ã©es automatiquement : `events_YYYYMMDD` (une par jour)
- Table intraday : `events_intraday_YYYYMMDD` (si streaming activÃ©)
- SchÃ©ma nested avec Ã©vÃ©nements, paramÃ¨tres, user properties

---

#### 7.3 - Google Ads â†’ BigQuery

**Export NATIF Google Ads vers BigQuery**

âš ï¸ **PrÃ©requis :** Compte Google Ads avec droits administrateur

1. Se connecter Ã  [Google Ads](https://ads.google.com/)
2. Menu **"Outils et paramÃ¨tres"** (ğŸ”§) â†’ **"Configuration"** â†’ **"Exports BigQuery"**
3. Cliquer sur le bouton **+** (Nouvel export)
4. Configurer :
   - **Projet Google Cloud** : SÃ©lectionner votre projet
   - **Dataset** : CrÃ©er `google_ads` ou utiliser existant
   - **Emplacement des donnÃ©es** : `EU` ou `US`
   - **Tables Ã  exporter** : SÃ©lectionner les tables nÃ©cessaires
     - âœ… Campaign (campagnes)
     - âœ… Ad Group (groupes d'annonces)
     - âœ… Ad (annonces)
     - âœ… Keyword (mots-clÃ©s)
     - âœ… Search Term (termes de recherche)
     - âœ… Geo (gÃ©ographie)
     - âœ… Click (clics)
     - Etc.
   - **FrÃ©quence** : Quotidienne (automatique chaque nuit)
5. Cliquer sur **"CrÃ©er"**

**RÃ©sultat :**
- Tables crÃ©Ã©es : `Campaign_XXXXXXXX`, `AdGroup_XXXXXXXX`, etc.
- Mise Ã  jour quotidienne automatique
- Historique : jusqu'Ã  13 mois de donnÃ©es

---

#### 7.4 - RÃ©sumÃ© des datasets crÃ©Ã©s

AprÃ¨s configuration, vous aurez ces datasets dans BigQuery :

```
votre-project-id
â”œâ”€â”€ linkedin_ads_advertising    # Scripts Python (campagnes, budgets, creatives)
â”œâ”€â”€ linkedin_ads_library        # Scripts Python (surveillance concurrence)
â”œâ”€â”€ linkedin_leadgen_form       # Scripts Python (formulaires leads)
â”œâ”€â”€ linkedin_page               # Scripts Python (statistiques page)
â”œâ”€â”€ microsoft_clarity           # Scripts Python (comportement utilisateur)
â”œâ”€â”€ spyfu                       # Scripts Python (SEO/PPC concurrentiel)
â”œâ”€â”€ google_search_console       # ğŸ”— Connexion native GSC
â”œâ”€â”€ analytics_XXXXXXXXX         # ğŸ”— Connexion native GA4
â””â”€â”€ google_ads                  # ğŸ”— Connexion native Google Ads
```

**Avantages des connexions natives :**
- âœ… Aucun code Ã  Ã©crire
- âœ… Synchronisation automatique quotidienne
- âœ… Gratuit (sauf streaming GA4 au-delÃ  de 1M Ã©vÃ©nements)
- âœ… DonnÃ©es historiques disponibles
- âœ… SchÃ©ma maintenu par Google
- âœ… Pas de gestion d'API keys

---

### Ã‰tape 8 : VÃ©rifier la configuration

```sql
-- VÃ©rifier que les datasets existent
SELECT schema_name
FROM INFORMATION_SCHEMA.SCHEMATA;

-- VÃ©rifier les tables LinkedIn
SELECT table_name
FROM `linkedin.INFORMATION_SCHEMA.TABLES`;

-- VÃ©rifier les tables Clarity
SELECT table_name
FROM `microsoft_clarity.INFORMATION_SCHEMA.TABLES`;

-- VÃ©rifier les tables SpyFu
SELECT table_name
FROM `spyfu.INFORMATION_SCHEMA.TABLES`;
```

---

## ğŸ” Configuration LinkedIn

### Vue d'ensemble OAuth 2.0

LinkedIn utilise OAuth 2.0 avec un **Refresh Token** qui ne change pas et permet de gÃ©nÃ©rer des **Access Tokens** temporaires (60 jours).

âš ï¸ **Important :** Tous les credentials collectÃ©s dans cette section devront Ãªtre renseignÃ©s dans le fichier `config.yaml` (voir Ã‰tape 6). Les scripts lisent automatiquement leurs configurations depuis ce fichier centralisÃ©.

âš ï¸ **Important :** Tous les credentials collectÃ©s dans cette section devront Ãªtre renseignÃ©s dans le fichier `config.yaml` (voir Ã‰tape 6). Les scripts lisent automatiquement leurs configurations depuis ce fichier centralisÃ©.

**Flux OAuth :**
```
1. CrÃ©er une App LinkedIn
2. Obtenir Client ID + Client Secret
3. GÃ©nÃ©rer un Authorization Code (via navigateur)
4. Ã‰changer le code contre un Refresh Token
5. Renseigner tous les credentials dans config.yaml
5. Renseigner tous les credentials dans config.yaml
   â†’ Les scripts gÃ©nÃ¨rent automatiquement les Access Tokens
```

---

### Ã‰tape 1 : CrÃ©er une application LinkedIn

1. Aller sur [LinkedIn Developers](https://www.linkedin.com/developers/)
2. Se connecter avec votre compte LinkedIn
3. Cliquer sur **"Create app"**

4. Remplir le formulaire :
   - **App name** : `Marketing Data Collector`
   - **LinkedIn Page** : SÃ©lectionner votre page entreprise
     - âš ï¸ **Vous devez Ãªtre admin de la page**
     - Si pas de page : crÃ©er une page entreprise d'abord
   - **Privacy policy URL** : URL de votre politique de confidentialitÃ©
   - **App logo** : Upload un logo (256x256px minimum)
   - **Legal agreement** : Cocher la case

5. Cliquer sur **"Create app"**

---

### Ã‰tape 2 : Demander l'accÃ¨s aux produits

1. Dans votre app, onglet **"Products"**
2. Demander l'accÃ¨s Ã  :
   - âœ… **Marketing Developer Platform**
   - âœ… **Advertising API**

3. Pour chaque produit :
   - Cliquer sur **"Request access"**
   - Remplir le formulaire de demande
   - Expliquer l'usage : "Automated data collection for internal marketing analytics"

â±ï¸ **DÃ©lai d'approbation :** 1-7 jours ouvrÃ©s

ğŸ“§ **Notification :** Email de confirmation une fois approuvÃ©

---

### Ã‰tape 3 : Configurer OAuth 2.0

1. Onglet **"Auth"**
2. **Redirect URLs** â†’ Cliquer sur le crayon pour Ã©diter
3. Ajouter :
   ```
   http://localhost:8080/callback
   ```
4. Cliquer sur **"Update"**

5. **Noter vos credentials** :
   - **Client ID** : `78...` (long string)
   - **Client Secret** : `WP...` (long string)

âš ï¸ **Ne jamais partager** ces credentials !

---

### Ã‰tape 4 : Obtenir l'Ad Account ID

1. Aller sur [LinkedIn Campaign Manager](https://www.linkedin.com/campaignmanager/)
2. L'URL contient votre Account ID :
   ```
   https://www.linkedin.com/campaignmanager/accounts/503061133/
                                                    ^^^^^^^^^^
                                                    Account ID
   ```
3. **Noter cet ID**

---

### Ã‰tape 5 : Configurer config.yaml avec Client ID et Client Secret

âš ï¸ **Important :** Avant de gÃ©nÃ©rer le Refresh Token, vous devez d'abord renseigner le Client ID et le Client Secret dans `config.yaml`.

1. **Ouvrir** `config.yaml` (ou crÃ©er depuis `config.example.yaml`)

   ```bash
   cd /home/cseceh/Deep_Scouting/admin/Projet_Ads/code
   nano config.yaml
   ```

2. **Remplir la section LinkedIn OAuth** avec les informations de l'Ã‰tape 3 :

   ```yaml
   linkedin:
     oauth:
       client_id: "78xxxxxxxxxxxxxxxx"      # Client ID de l'Ã‰tape 3
       client_secret: "WPxxxxxxxxxxxxxxxx"  # Client Secret de l'Ã‰tape 3
       refresh_token: ""                    # Sera rempli aprÃ¨s l'Ã‰tape 6
       redirect_uri: "http://localhost:8080/callback"  # Doit correspondre Ã  l'Ã‰tape 3
       scopes:  # Scopes par dÃ©faut (peut Ãªtre modifiÃ© si nÃ©cessaire)
         - "r_ads"
         - "rw_ads"
         - "r_ads_reporting"
         - "r_ads_leadgen_automation"
   
     account_id: "503061133"  # Ad Account ID de l'Ã‰tape 4
   
     collection:
       start_date: "2024-01-01"
       end_date: null  # null = aujourd'hui
       granularity: "DAILY"
       api_version: "202509"
   
     analytics:
       pivots:
         - "CAMPAIGN"
         - "CREATIVE"
   ```

3. **Sauvegarder** le fichier

4. **SÃ©curiser** le fichier

   ```bash
   chmod 600 config.yaml
   ```

âš ï¸ **Laissez `refresh_token` vide pour le moment** - Il sera gÃ©nÃ©rÃ© Ã  l'Ã©tape suivante.

---

### Ã‰tape 6 : GÃ©nÃ©rer le Refresh Token

Le Refresh Token est un token permanent qui permet aux scripts de gÃ©nÃ©rer automatiquement des Access Tokens.

âš ï¸ **PrÃ©requis :** Le fichier `config.yaml` doit Ãªtre configurÃ© avec `client_id` et `client_secret` (Ã‰tape 5).

**Processus :**

1. **ExÃ©cuter le script de gÃ©nÃ©ration de token**

   Le script `token_linkedin.py` lit automatiquement les credentials depuis `config.yaml` :

   ```bash
   cd linkedin/scripts
   python token_linkedin.py
   ```

2. **Autoriser dans le navigateur**
   - Une page LinkedIn s'ouvre automatiquement
   - Se connecter avec votre compte LinkedIn
   - Cliquer sur **"Autoriser"** pour donner les permissions

3. **Le script rÃ©cupÃ¨re automatiquement le code**
   - Si `redirect_uri` est `localhost` : le code est capturÃ© automatiquement
   - Sinon : copier le code depuis l'URL de redirection

4. **Le Refresh Token est affichÃ© dans le terminal**

   ```
   â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
   â•‘               âœ“ ACCESS TOKEN GÃ‰NÃ‰RÃ‰ AVEC SUCCÃˆS!                  â•‘
   â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
   
   Access Token:
   AQV...xxxxxxxxxxxxxxxxxx...
   
   Refresh Token:
   AQV...yyyyyyyyyyyyyyyyyy...
   ```

5. **Copier le Refresh Token affichÃ©** (la longue chaÃ®ne commenÃ§ant par `AQV`)

---

### Ã‰tape 7 : Ajouter le Refresh Token dans config.yaml

1. **Rouvrir** `config.yaml`

   ```bash
   nano config.yaml
   ```

2. **Ajouter le Refresh Token** dans la section LinkedIn OAuth :

   ```yaml
   linkedin:
     oauth:
       client_id: "78xxxxxxxxxxxxxxxx"
       client_secret: "WPxxxxxxxxxxxxxxxx"
       refresh_token: "AQVxxxxxxxxxxxxxxxx"  # â† COLLER LE REFRESH TOKEN ICI
       redirect_uri: "http://localhost:8080/callback"
   ```

3. **Sauvegarder** le fichier

âœ… **Configuration terminÃ©e !** Les scripts LinkedIn liront automatiquement tous les credentials depuis `config.yaml`.

**Voir aussi :** Documentation complÃ¨te dans [linkedin/README.md](linkedin/README.md) section "Configuration OAuth".
### Ã‰tape 5 : Configurer config.yaml avec Client ID et Client Secret

âš ï¸ **Important :** Avant de gÃ©nÃ©rer le Refresh Token, vous devez d'abord renseigner le Client ID et le Client Secret dans `config.yaml`.

1. **Ouvrir** `config.yaml` (ou crÃ©er depuis `config.example.yaml`)

   ```bash
   cd /home/cseceh/Deep_Scouting/admin/Projet_Ads/code
   nano config.yaml
   ```

2. **Remplir la section LinkedIn OAuth** avec les informations de l'Ã‰tape 3 :

   ```yaml
   linkedin:
     oauth:
       client_id: "78xxxxxxxxxxxxxxxx"      # Client ID de l'Ã‰tape 3
       client_secret: "WPxxxxxxxxxxxxxxxx"  # Client Secret de l'Ã‰tape 3
       refresh_token: ""                    # Sera rempli aprÃ¨s l'Ã‰tape 6
       redirect_uri: "http://localhost:8080/callback"  # Doit correspondre Ã  l'Ã‰tape 3
       scopes:  # Scopes par dÃ©faut (peut Ãªtre modifiÃ© si nÃ©cessaire)
         - "r_ads"
         - "rw_ads"
         - "r_ads_reporting"
         - "r_ads_leadgen_automation"
   
     account_id: "503061133"  # Ad Account ID de l'Ã‰tape 4
   
     collection:
       start_date: "2024-01-01"
       end_date: null  # null = aujourd'hui
       granularity: "DAILY"
       api_version: "202509"
   
     analytics:
       pivots:
         - "CAMPAIGN"
         - "CREATIVE"
   ```

3. **Sauvegarder** le fichier

4. **SÃ©curiser** le fichier

   ```bash
   chmod 600 config.yaml
   ```

âš ï¸ **Laissez `refresh_token` vide pour le moment** - Il sera gÃ©nÃ©rÃ© Ã  l'Ã©tape suivante.

---

### Ã‰tape 6 : GÃ©nÃ©rer le Refresh Token

Le Refresh Token est un token permanent qui permet aux scripts de gÃ©nÃ©rer automatiquement des Access Tokens.

âš ï¸ **PrÃ©requis :** Le fichier `config.yaml` doit Ãªtre configurÃ© avec `client_id` et `client_secret` (Ã‰tape 5).

**Processus :**

1. **ExÃ©cuter le script de gÃ©nÃ©ration de token**

   Le script `token_linkedin.py` lit automatiquement les credentials depuis `config.yaml` :

   ```bash
   cd linkedin/scripts
   python token_linkedin.py
   ```

2. **Autoriser dans le navigateur**
   - Une page LinkedIn s'ouvre automatiquement
   - Se connecter avec votre compte LinkedIn
   - Cliquer sur **"Autoriser"** pour donner les permissions

3. **Le script rÃ©cupÃ¨re automatiquement le code**
   - Si `redirect_uri` est `localhost` : le code est capturÃ© automatiquement
   - Sinon : copier le code depuis l'URL de redirection

4. **Le Refresh Token est affichÃ© dans le terminal**

   ```
   â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
   â•‘               âœ“ ACCESS TOKEN GÃ‰NÃ‰RÃ‰ AVEC SUCCÃˆS!                  â•‘
   â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
   
   Access Token:
   AQV...xxxxxxxxxxxxxxxxxx...
   
   Refresh Token:
   AQV...yyyyyyyyyyyyyyyyyy...
   ```

5. **Copier le Refresh Token affichÃ©** (la longue chaÃ®ne commenÃ§ant par `AQV`)

---

### Ã‰tape 7 : Ajouter le Refresh Token dans config.yaml

1. **Rouvrir** `config.yaml`

   ```bash
   nano config.yaml
   ```

2. **Ajouter le Refresh Token** dans la section LinkedIn OAuth :

   ```yaml
   linkedin:
     oauth:
       client_id: "78xxxxxxxxxxxxxxxx"
       client_secret: "WPxxxxxxxxxxxxxxxx"
       refresh_token: "AQVxxxxxxxxxxxxxxxx"  # â† COLLER LE REFRESH TOKEN ICI
       redirect_uri: "http://localhost:8080/callback"
   ```

3. **Sauvegarder** le fichier

âœ… **Configuration terminÃ©e !** Les scripts LinkedIn liront automatiquement tous les credentials depuis `config.yaml`.

**Voir aussi :** Documentation complÃ¨te dans [linkedin/README.md](linkedin/README.md) section "Configuration OAuth".

---

## ğŸ” Configuration Microsoft Clarity

### Ã‰tape 1-3 : Configuration du projet

Voir [microsoft_clarity/README.md](microsoft_clarity/README.md) pour les Ã©tapes dÃ©taillÃ©es :
1. CrÃ©er un projet Clarity
2. Installer le tracking code
3. Obtenir Project ID et API Key

---

## ğŸ¯ Configuration SpyFu

### Obtenir l'API Key

Voir [spyfu/README.md](spyfu/README.md) pour les Ã©tapes dÃ©taillÃ©es.

**RÃ©sumÃ© :**
1. Se connecter Ã  SpyFu (abonnement requis)
2. Account Settings â†’ API
3. Copier la **Secret Key**

---

## ğŸš€ DÃ©ploiement et exÃ©cution

### Structure de fichiers finale

```
marketing-data-collection/        # Repository clonÃ© depuis GitHub
â”œâ”€â”€ account-key.json              # Ã€ crÃ©er (Service Account GCP - NE PAS COMMIT)
â”œâ”€â”€ linkedin/
â”‚   â”œâ”€â”€ scripts/                  # 5 scripts Python
â”‚   â”œâ”€â”€ sql/                      # 5 fichiers SQL
â”‚   â”œâ”€â”€ data/                     # JSON backups (crÃ©Ã© automatiquement)
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ microsoft_clarity/
â”‚   â”œâ”€â”€ scripts/                  # 1 script Python
â”‚   â”œâ”€â”€ sql/                      # 1 fichier SQL
â”‚   â”œâ”€â”€ data/                     # JSON backups (crÃ©Ã© automatiquement)
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ spyfu/
â”‚   â”œâ”€â”€ scripts/                  # 8 scripts Python
â”‚   â”œâ”€â”€ sql/                      # 1 fichier SQL
â”‚   â”œâ”€â”€ data/                     # JSON backups (crÃ©Ã© automatiquement)
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ SETUP_GUIDE.md                # Ce fichier
â”œâ”€â”€ README.md                     # Documentation principale
â””â”€â”€ .gitignore                    # ProtÃ¨ge les credentials
```

---

### ExÃ©cution manuelle

```bash
# Se placer dans le dossier du repository clonÃ©
cd marketing-data-collection

# LinkedIn
cd linkedin/scripts
python linkedin_campaign_analytics.py
python linkedin_budget.py
python linkedin_lead_forms.py
python linkedin_page_stats.py
python linkedin_ads_library.py

# Clarity
cd ../../microsoft_clarity/scripts
python clarity_analytics.py

# SpyFu
cd ../../spyfu/scripts
python spyfu_ppc_keywords.py
python spyfu_seo_keywords.py
# ... autres scripts
```

---

## ğŸ”’ SÃ©curitÃ© et bonnes pratiques

### .gitignore (dÃ©jÃ  inclus dans le repository)

Le repository contient dÃ©jÃ  un `.gitignore` qui protÃ¨ge automatiquement :

```gitignore
# Fichiers de configuration sensibles
config.yaml              # âš ï¸ Contient tous les credentials (LinkedIn, Clarity, SpyFu)
account-key.json         # Service Account Google Cloud
# Fichiers de configuration sensibles
config.yaml              # âš ï¸ Contient tous les credentials (LinkedIn, Clarity, SpyFu)
account-key.json         # Service Account Google Cloud

# Tokens
*_token.txt
.env

# Data exports (JSON backups)
linkedin/data/*.json
microsoft_clarity/data/*.json
spyfu/data/*.json

# Python
__pycache__/
*.pyc
venv/
.venv/

# Logs
*.log
```

âš ï¸ **Fichiers Ã  ne JAMAIS commiter :**
- `config.yaml` - Contient tous vos credentials (LinkedIn OAuth, API keys, etc.)
- `account-key.json` - ClÃ© du Service Account Google Cloud

âš ï¸ **Fichiers Ã  ne JAMAIS commiter :**
- `config.yaml` - Contient tous vos credentials (LinkedIn OAuth, API keys, etc.)
- `account-key.json` - ClÃ© du Service Account Google Cloud

âš ï¸ **Ne jamais modifier le .gitignore pour Ã©viter de commit des credentials !**

---

### Permissions fichiers

```bash
# SÃ©curiser le Service Account key
chmod 600 account-key.json

# Scripts exÃ©cutables
chmod 755 linkedin/scripts/*.py
chmod 755 microsoft_clarity/scripts/*.py
chmod 755 spyfu/scripts/*.py
```

---

## â° Automatisation

### FrÃ©quences recommandÃ©es

| Source | Script | FrÃ©quence | Raison |
|--------|--------|-----------|--------|
| Clarity | clarity_analytics | **Quotidien (2h)** | **API limitÃ©e Ã  3 jours** |
| LinkedIn | campaign_analytics | Quotidien (3h) | MÃ©triques jour J-1 |
| LinkedIn | lead_forms | 2x/jour (8h, 18h) | RÃ©activitÃ© sur leads |
| LinkedIn | ads_library | Quotidien/Hebdomadaire | Surveillance concurrence |
| SpyFu | ppc/seo_keywords | Hebdomadaire | Ã‰conomiser API calls |

### Cron jobs

```bash
crontab -e
```

Ajouter :

```bash
# Variables (adapter selon votre installation)
REPO_DIR=/home/user/marketing-data-collection
PYTHON=/usr/bin/python3  # ou le chemin vers votre venv

# Clarity - QUOTIDIEN OBLIGATOIRE
0 2 * * * cd $REPO_DIR/microsoft_clarity/scripts && $PYTHON clarity_analytics.py >> /var/log/clarity.log 2>&1

# LinkedIn Analytics - Quotidien
0 3 * * * cd $REPO_DIR/linkedin/scripts && $PYTHON linkedin_campaign_analytics.py >> /var/log/linkedin.log 2>&1

# LinkedIn Leads - 2x/jour
0 8,18 * * * cd $REPO_DIR/linkedin/scripts && $PYTHON linkedin_lead_forms.py >> /var/log/linkedin_leads.log 2>&1

# LinkedIn Ads Library - Quotidien (4h) pour surveillance concurrence
0 4 * * * cd $REPO_DIR/linkedin/scripts && $PYTHON linkedin_ads_library.py >> /var/log/linkedin_ads_library.log 2>&1

# SpyFu - Hebdomadaire (dimanche)
0 5 * * 0 cd $REPO_DIR/spyfu/scripts && $PYTHON spyfu_ppc_keywords.py >> /var/log/spyfu.log 2>&1
```

---

## âš™ï¸ Configuration dÃ©taillÃ©e

### Fichier config.yaml

Le fichier `config.yaml` centralise tous les paramÃ¨tres du projet. Voici comment le remplir section par section :

#### 1. Google Cloud & BigQuery

```yaml
google_cloud:
  project_id: "votre-project-id"  # ID de votre projet GCP
  credentials_file: "./account-key.json"  # Chemin vers le Service Account

  datasets:
    linkedin: "linkedin"  # Nom du dataset pour LinkedIn
    clarity: "microsoft_clarity"  # Nom du dataset pour Clarity
    spyfu: "spyfu"  # Nom du dataset pour SpyFu

  location: "EU"  # EU, US, ou autre rÃ©gion
```

#### 2. LinkedIn

âš ï¸ **Important :** Les credentials OAuth LinkedIn (Client ID, Client Secret, Refresh Token) doivent Ãªtre renseignÃ©s dans ce fichier `config.yaml`. Les scripts lisent automatiquement ces informations depuis ce fichier.

âš ï¸ **Important :** Les credentials OAuth LinkedIn (Client ID, Client Secret, Refresh Token) doivent Ãªtre renseignÃ©s dans ce fichier `config.yaml`. Les scripts lisent automatiquement ces informations depuis ce fichier.

```yaml
linkedin:
  oauth:
    client_id: "78xxxxxxxxxxxxxxxx"  # Client ID depuis LinkedIn App (Ã‰tape 3)
    client_secret: "WPxxxxxxxxxxxxxxxx"  # Client Secret depuis LinkedIn App (Ã‰tape 3)
    refresh_token: "AQVxxxxxxxxxxxxxxxx"  # Refresh Token gÃ©nÃ©rÃ© via token_linkedin.py (Ã‰tape 5)
    access_token: "AQWxxxxxxxxxxxxxxxx"  # Access Token (gÃ©nÃ©rÃ© automatiquement ou manuellement)

  account_id: "503061133"  # Votre Ad Account ID (Ã‰tape 4)
  organization_id: "5509810"  # Organization ID pour page stats et lead forms

  collection:
    start_date: "2024-01-01"  # Date de dÃ©but de collecte
    end_date: null  # null = aujourd'hui
    granularity: "DAILY"  # DAILY, MONTHLY, YEARLY, ALL
    api_version: "202509"  # Version API LinkedIn

  analytics:
    pivots:
      - "CAMPAIGN"  # DonnÃ©es par campagne
      - "CREATIVE"  # DonnÃ©es par creative

  # Ads Library - Surveillance des publicitÃ©s concurrentes
  ads_library:
    # Mots-clÃ©s Ã  rechercher dans les publicitÃ©s
    # Utilisez des termes liÃ©s Ã  votre secteur d'activitÃ©
    keywords:
      - "marketing digital"
      - "formation"
      - "intelligence artificielle"
      - "data science"

    # Annonceurs spÃ©cifiques Ã  surveiller (noms EXACTS)
    # IMPORTANT: Utilisez le nom exact tel qu'il apparaÃ®t sur LinkedIn
    # Pour trouver le nom exact :
    #   1. Cherchez la page LinkedIn de votre concurrent
    #   2. Le nom exact est affichÃ© en haut de la page
    advertisers:
      - "HEC Paris"
      - "ESSEC Business School"
      - "ESCP Business School"
      - "emlyon business school"

    # Pays Ã  cibler (codes ISO Ã  2 lettres en MINUSCULES)
    countries:
      - "fr"  # France
      - "us"  # Ã‰tats-Unis
      # - "gb"  # Royaume-Uni
      # - "de"  # Allemagne
      # - "es"  # Espagne
      # - "it"  # Italie

    # Maximum de rÃ©sultats par recherche
    # L'API LinkedIn retourne 25 rÃ©sultats par page
    # Cette valeur dÃ©finit le nombre total maximum Ã  rÃ©cupÃ©rer
    max_results_per_search: 500

    # DÃ©lai entre les requÃªtes API (en secondes)
    # IMPORTANT: Ne pas descendre en dessous de 2.0 pour Ã©viter les erreurs 429
    # L'API LinkedIn limite Ã  environ 30 requÃªtes par minute
    request_delay: 2.0
```

**Notes sur la configuration Ads Library :**

1. **Keywords vs Advertisers** :
   - Vous pouvez utiliser uniquement `keywords`, uniquement `advertisers`, ou les deux
   - Au moins l'un des deux doit Ãªtre renseignÃ© (non vide)
   - `keywords` : Recherche large dans toutes les publicitÃ©s contenant ces mots
   - `advertisers` : Recherche ciblÃ©e sur des annonceurs spÃ©cifiques

2. **Nom exact des annonceurs** :
   - Le nom doit correspondre EXACTEMENT au nom de la page LinkedIn
   - Sensible Ã  la casse (majuscules/minuscules)
   - Sensible aux espaces et caractÃ¨res spÃ©ciaux
   - Astuce : Recherchez "SKEMA BUSINESS SCHOOL" si c'est le nom exact sur LinkedIn

3. **Codes pays** :
   - Utilisez les codes ISO 3166-1 alpha-2 (2 lettres)
   - Toujours en **minuscules** : `"fr"` et non `"FR"`
   - Liste complÃ¨te : https://en.wikipedia.org/wiki/ISO_3166-1_alpha-2

4. **Rate limiting** :
   - L'API limite Ã  ~30 requÃªtes par minute
   - Le paramÃ¨tre `request_delay: 2.0` ajoute 2 secondes entre chaque requÃªte
   - En cas d'erreur 429 (trop de requÃªtes), le script attend automatiquement
   - Augmentez `request_delay` Ã  3.0 ou 5.0 si vous avez beaucoup d'erreurs 429

5. **DonnÃ©es collectÃ©es** :
   - URL de la publicitÃ©
   - Nom de l'annonceur
   - Type de publicitÃ© (SPONSORED_VIDEO, SPONSORED_CONTENT, etc.)
   - Dates de premiÃ¨re et derniÃ¨re impression
   - Fourchette d'impressions
   - Distribution par pays
   - Informations de ciblage (segments)

**Exemple de configuration complÃ¨te :**

```yaml
linkedin:
  ads_library:
    # Recherche par mots-clÃ©s dans le secteur Ã©ducation
    keywords:
      - "MBA"
      - "Executive Education"
      - "Business School"
      - "Formation continue"
      - "Grande Ã‰cole"

    # Surveillance de 5 concurrents directs
    advertisers:
      - "HEC Paris"
      - "INSEAD"
      - "ESSEC Business School"
      - "ESCP Business School"
      - "emlyon business school"

    # Ciblage France uniquement
    countries:
      - "fr"

    # Limite Ã  250 pubs par recherche (Ã©conomiser les appels API)
    max_results_per_search: 250

    # DÃ©lai de 3 secondes pour Ãªtre plus prudent
    request_delay: 3.0
```

#### 3. Microsoft Clarity

```yaml
microsoft_clarity:
  project_id: "neutnvggsv"  # Project ID Clarity
  api_key: "VOTRE_API_KEY"  # Token JWT depuis Clarity

  api:
    base_url: "https://www.clarity.ms/api/project-live-insights"
    num_of_days: 1  # 1, 2 ou 3 maximum (limitation API)
```

âš ï¸ **Important:** L'API Clarity limite Ã  3 jours maximum. Collecte quotidienne OBLIGATOIRE.

#### 4. SpyFu

```yaml
spyfu:
  api_key: "VOTRE_SECRET_KEY"  # Secret Key (pas l'ID !)

  global:
    country_code: "FR"  # FR, US, DE, GB, etc.
    page_size: 1000  # Nombre de rÃ©sultats par requÃªte

  domains:
    primary: "votre-domaine.com"  # Votre domaine principal

    competitors:  # Liste de concurrents Ã  surveiller
      - "concurrent1.com"
      - "concurrent2.com"
      - "concurrent3.com"

  comparisons:  # Comparaisons SEO (outrank_comparison)
    - domain: "votre-domaine.com"
      compare_domain: "concurrent1.com"

    - domain: "votre-domaine.com"
      compare_domain: "concurrent2.com"

  filters:  # Filtres globaux
    min_search_volume: 100  # Volume de recherche minimum
    max_keyword_difficulty: 80  # DifficultÃ© maximum
    max_cost_per_click: 50.0  # CPC maximum

  # Configuration par endpoint
  ppc_keywords:
    enabled: true
    sort_by: "SearchVolume"
    filters:
      min_search_volume: 100

  seo_keywords:
    enabled: true
    search_type: "MostValuable"  # MostValuable, GainedClicks, etc.
    filters:
      min_search_volume: 100
      min_seo_clicks: 10
```

**Endpoints disponibles:**
- `ppc_keywords` - Mots-clÃ©s PPC
- `new_keywords` - Nouveaux mots-clÃ©s
- `paid_serps` - SERPs payants
- `seo_keywords` - Mots-clÃ©s SEO
- `newly_ranked` - Nouveaux rankings
- `outrank_comparison` - Comparaisons de ranking
- `top_pages` - Pages les plus performantes
- `ppc_competitors` - Concurrents PPC

#### 5. Automatisation

```yaml
automation:
  schedules:
    linkedin:
      campaign_analytics: "daily"  # Quotidien Ã  3h
      budget: "weekly"  # Hebdomadaire
      lead_forms: "twice_daily"  # 2x/jour

    clarity:
      analytics: "daily"  # OBLIGATOIRE quotidien

    spyfu:
      ppc_keywords: "weekly"  # Hebdomadaire
      seo_keywords: "weekly"
      other: "monthly"  # Autres endpoints
```

#### 6. DÃ©veloppement & Debug

```yaml
development:
  debug_mode: false  # Mode debug (verbose)
  dry_run: false  # Test sans upload BigQuery
  limit_results: null  # Limiter rÃ©sultats (ex: 10 pour tests)
  verbose: false  # Logging dÃ©taillÃ©
```

### Utilisation dans les scripts

Les scripts chargent automatiquement la configuration :

```python
from config_loader import load_config

# Charger la config
config = load_config()

# AccÃ©der aux valeurs
linkedin_config = config.get_linkedin_config()
spyfu_config = config.get_spyfu_config()

# Ou accÃ¨s direct par chemin
project_id = config.get('google_cloud.project_id')
domains = config.get('spyfu.domains.all')
```

### Validation de la configuration

```bash
# Tester la configuration
python config_loader.py

# Affiche :
# âœ“ Configuration chargÃ©e depuis config.yaml
# Configuration Summary
# ======================================
# Google Cloud: clean-avatar-466709-a0
# LinkedIn: 503061133
# SpyFu: votre-domaine.com (3 competitors)
# ...
```

---

## ğŸ”§ Troubleshooting global

### ProblÃ¨mes courants

#### Permission denied

```bash
chmod 600 account-key.json
```

#### Module not found

```bash
pip install pandas-gbq google-auth
```

#### BigQuery access denied

VÃ©rifier les rÃ´les du Service Account :
- BigQuery Data Editor
- BigQuery Job User

#### API rate limiting

Attendre et espacer les requÃªtes.

---

## âœ… Checklist de dÃ©ploiement

### Configuration initiale

- [ ] Repository clonÃ© depuis GitHub
- [ ] Fichier `config.yaml` crÃ©Ã© depuis `config.example.yaml`
- [ ] DÃ©pendances Python installÃ©es (`requirements.txt`)

### Configuration initiale

- [ ] Repository clonÃ© depuis GitHub
- [ ] Fichier `config.yaml` crÃ©Ã© depuis `config.example.yaml`
- [ ] DÃ©pendances Python installÃ©es (`requirements.txt`)

### Google Cloud

- [ ] Projet GCP crÃ©Ã©
- [ ] BigQuery API activÃ©e
- [ ] Service Account crÃ©Ã© avec permissions
- [ ] ClÃ© JSON tÃ©lÃ©chargÃ©e et renommÃ©e `account-key.json`
- [ ] `account-key.json` sÃ©curisÃ© (chmod 600)
- [ ] Project ID ajoutÃ© dans `config.yaml`
- [ ] 6 datasets crÃ©Ã©s (linkedin x4, clarity, spyfu)
- [ ] Tables crÃ©Ã©es depuis SQL (via `setup_bigquery.py`)
- [ ] ClÃ© JSON tÃ©lÃ©chargÃ©e et renommÃ©e `account-key.json`
- [ ] `account-key.json` sÃ©curisÃ© (chmod 600)
- [ ] Project ID ajoutÃ© dans `config.yaml`
- [ ] 6 datasets crÃ©Ã©s (linkedin x4, clarity, spyfu)
- [ ] Tables crÃ©Ã©es depuis SQL (via `setup_bigquery.py`)

### LinkedIn

- [ ] App LinkedIn crÃ©Ã©e
- [ ] Marketing Developer Platform approuvÃ©
- [ ] Client ID et Client Secret rÃ©cupÃ©rÃ©s (Ã‰tape 3)
- [ ] Redirect URL configurÃ© : `http://localhost:8080/callback` (Ã‰tape 3)
- [ ] Ad Account ID rÃ©cupÃ©rÃ© (Ã‰tape 4)
- [ ] **Client ID et Client Secret ajoutÃ©s dans `config.yaml`** (Ã‰tape 5)
- [ ] Refresh Token gÃ©nÃ©rÃ© via `token_linkedin.py` (Ã‰tape 6)
- [ ] **Refresh Token ajoutÃ© dans `config.yaml`** (Ã‰tape 7)
- [ ] Client ID et Client Secret rÃ©cupÃ©rÃ©s (Ã‰tape 3)
- [ ] Redirect URL configurÃ© : `http://localhost:8080/callback` (Ã‰tape 3)
- [ ] Ad Account ID rÃ©cupÃ©rÃ© (Ã‰tape 4)
- [ ] **Client ID et Client Secret ajoutÃ©s dans `config.yaml`** (Ã‰tape 5)
- [ ] Refresh Token gÃ©nÃ©rÃ© via `token_linkedin.py` (Ã‰tape 6)
- [ ] **Refresh Token ajoutÃ© dans `config.yaml`** (Ã‰tape 7)

### Clarity

- [ ] Projet Clarity crÃ©Ã©
- [ ] Tracking code installÃ© sur le site
- [ ] Project ID rÃ©cupÃ©rÃ©
- [ ] API Key (JWT) rÃ©cupÃ©rÃ©e
- [ ] **Credentials ajoutÃ©s dans `config.yaml`** (project_id, api_key)
- [ ] Tracking code installÃ© sur le site
- [ ] Project ID rÃ©cupÃ©rÃ©
- [ ] API Key (JWT) rÃ©cupÃ©rÃ©e
- [ ] **Credentials ajoutÃ©s dans `config.yaml`** (project_id, api_key)

### SpyFu

- [ ] API Secret Key rÃ©cupÃ©rÃ©e depuis compte SpyFu
- [ ] Domaines Ã  surveiller dÃ©finis
- [ ] Concurrents identifiÃ©s
- [ ] **Credentials et domaines ajoutÃ©s dans `config.yaml`** (api_key, domains, competitors)
- [ ] API Secret Key rÃ©cupÃ©rÃ©e depuis compte SpyFu
- [ ] Domaines Ã  surveiller dÃ©finis
- [ ] Concurrents identifiÃ©s
- [ ] **Credentials et domaines ajoutÃ©s dans `config.yaml`** (api_key, domains, competitors)

### Tests

- [ ] Test LinkedIn analytics
- [ ] Test Clarity analytics
- [ ] Test SpyFu keywords
- [ ] VÃ©rification donnÃ©es BigQuery
- [ ] VÃ©rification JSON backups

### Automatisation

- [ ] Cron jobs configurÃ©s
- [ ] Logs directory crÃ©Ã©
- [ ] Monitoring mis en place

### SÃ©curitÃ©

- [ ] .gitignore configurÃ©
- [ ] Permissions fichiers correctes
- [ ] Credentials non commitÃ©s

---

## ğŸ“š Documentation dÃ©taillÃ©e

Pour plus de dÃ©tails sur chaque source :

- **[LinkedIn README](linkedin/README.md)** - Configuration OAuth complÃ¨te, 3 scripts, 7 tables
- **[Microsoft Clarity README](microsoft_clarity/README.md)** - MÃ©triques UX, interprÃ©tation, scores
- **[SpyFu README](spyfu/README.md)** - 8 endpoints, analyse SEO/PPC, 26 vues

---

### Documentation API

- [LinkedIn Marketing API](https://learn.microsoft.com/en-us/linkedin/marketing/)
- [Microsoft Clarity API](https://docs.microsoft.com/en-us/clarity/)
- [SpyFu API](https://www.spyfu.com/api)
- [BigQuery Documentation](https://cloud.google.com/bigquery/docs)

---

**Version:** 1.0
**DerniÃ¨re mise Ã  jour:** 2025-10-21
**Auteur:** Deep Scouting
