#!/usr/bin/env python3
"""
Script pour synchroniser des donn√©es historiques Brevo
Permet de sp√©cifier des dates de d√©but et fin personnalis√©es
"""

import argparse
import sys
import yaml
import logging
from datetime import datetime, date, timedelta
from pathlib import Path

# Importer nos modules
sys.path.insert(0, str(Path(__file__).parent / 'scripts'))

from fetch_campaigns import fetch_all_campaigns, transform_campaign
from fetch_events import fetch_events, transform_event
from fetch_contacts_lists import fetch_all_lists, transform_list
from fetch_smtp_reports import fetch_smtp_report, transform_report
from upload_to_bigquery import (
    upload_campaigns,
    upload_events,
    upload_contacts_lists,
    upload_smtp_reports
)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def load_config() -> dict:
    """Charge la configuration"""
    with open('config.yaml', 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)


def fetch_events_by_date_range(api_key: str, start_date: date, end_date: date) -> list:
    """
    R√©cup√®re les √©v√©nements pour une plage de dates sp√©cifique

    Args:
        api_key: Cl√© API Brevo
        start_date: Date de d√©but (incluse)
        end_date: Date de fin (incluse)

    Returns:
        Liste des √©v√©nements
    """
    import requests

    url = 'https://api.brevo.com/v3/smtp/statistics/events'
    headers = {
        'api-key': api_key,
        'accept': 'application/json'
    }

    all_events = []
    limit = 100
    offset = 0

    logger.info(f"üì• R√©cup√©ration des √©v√©nements du {start_date} au {end_date}...")

    while True:
        params = {
            'limit': limit,
            'offset': offset,
            'startDate': start_date.strftime('%Y-%m-%d'),
            'endDate': end_date.strftime('%Y-%m-%d'),
            'sort': 'desc'
        }

        try:
            response = requests.get(url, headers=headers, params=params, timeout=30)
            response.raise_for_status()

            data = response.json()
            events = data.get('events', [])

            if not events:
                break

            all_events.extend(events)
            logger.info(f"  ‚úì R√©cup√©r√© {len(events)} √©v√©nements (total: {len(all_events)})")

            if len(events) < limit:
                break

            offset += limit

            if offset > 10000:
                logger.warning("‚ö†Ô∏è  Limite de 10k √©v√©nements atteinte pour cette p√©riode")
                break

        except requests.exceptions.RequestException as e:
            logger.error(f"‚ùå Erreur: {e}")
            break

    logger.info(f"‚úÖ Total r√©cup√©r√©: {len(all_events)} √©v√©nements")
    return all_events


def sync_historical_events(config: dict, start_date: date, end_date: date):
    """
    Synchronise les √©v√©nements historiques par tranches de 30 jours
    (limite API Brevo)
    """
    api_key = config['brevo']['api_key']

    # Diviser en tranches de 30 jours maximum
    current_start = start_date
    total_events = 0

    logger.info("=" * 60)
    logger.info(f"üì® SYNCHRONISATION HISTORIQUE DES √âV√âNEMENTS")
    logger.info(f"  P√©riode totale: {start_date} ‚Üí {end_date}")
    logger.info("=" * 60)

    while current_start < end_date:
        # Calculer la fin de la tranche (max 30 jours)
        current_end = min(current_start + timedelta(days=30), end_date)

        logger.info(f"\nüìÖ Tranche: {current_start} ‚Üí {current_end}")

        # R√©cup√©rer les √©v√©nements
        events = fetch_events_by_date_range(api_key, current_start, current_end)

        if events:
            # Transformer
            retrieved_at = datetime.now()
            transformed = [transform_event(e, retrieved_at) for e in events]

            # Upload vers BigQuery
            upload_events(transformed, config)
            total_events += len(transformed)
        else:
            logger.warning(f"  ‚ö†Ô∏è  Aucun √©v√©nement pour cette p√©riode")

        # Passer √† la tranche suivante
        current_start = current_end + timedelta(days=1)

    logger.info("\n" + "=" * 60)
    logger.info(f"‚úÖ SYNCHRONISATION HISTORIQUE TERMIN√âE")
    logger.info(f"  Total √©v√©nements synchronis√©s: {total_events}")
    logger.info("=" * 60)


def main():
    """Fonction principale"""
    parser = argparse.ArgumentParser(
        description='Synchronise les donn√©es historiques Brevo vers BigQuery'
    )
    parser.add_argument(
        '--start-date',
        type=str,
        required=True,
        help='Date de d√©but (format: YYYY-MM-DD, ex: 2025-12-18)'
    )
    parser.add_argument(
        '--end-date',
        type=str,
        default=None,
        help='Date de fin (format: YYYY-MM-DD, d√©faut: hier)'
    )
    parser.add_argument(
        '--events-only',
        action='store_true',
        help='Synchroniser seulement les √©v√©nements'
    )
    parser.add_argument(
        '--campaigns-only',
        action='store_true',
        help='Synchroniser seulement les campagnes'
    )
    parser.add_argument(
        '--reports-only',
        action='store_true',
        help='Synchroniser seulement les rapports SMTP'
    )

    args = parser.parse_args()

    # Parser les dates
    try:
        start_date = datetime.strptime(args.start_date, '%Y-%m-%d').date()
    except ValueError:
        logger.error("‚ùå Format de date de d√©but invalide. Utilisez YYYY-MM-DD")
        sys.exit(1)

    if args.end_date:
        try:
            end_date = datetime.strptime(args.end_date, '%Y-%m-%d').date()
        except ValueError:
            logger.error("‚ùå Format de date de fin invalide. Utilisez YYYY-MM-DD")
            sys.exit(1)
    else:
        # Par d√©faut: hier
        end_date = date.today() - timedelta(days=1)

    # V√©rifications
    if start_date >= end_date:
        logger.error("‚ùå La date de d√©but doit √™tre avant la date de fin")
        sys.exit(1)

    days_diff = (end_date - start_date).days
    if days_diff > 90:
        logger.warning(f"‚ö†Ô∏è  P√©riode de {days_diff} jours demand√©e. Cela peut prendre du temps...")

    # Charger la config
    config = load_config()

    logger.info("\n" + "=" * 60)
    logger.info("üöÄ SYNCHRONISATION HISTORIQUE BREVO ‚Üí BIGQUERY")
    logger.info("=" * 60)
    logger.info(f"  Projet GCP: {config['google_cloud']['project_id']}")
    logger.info(f"  Dataset: {config['google_cloud']['datasets']['brevo']}")
    logger.info(f"  P√©riode: {start_date} ‚Üí {end_date} ({days_diff} jours)")
    logger.info("=" * 60 + "\n")

    try:
        # D√©terminer quoi synchroniser
        sync_all = not any([
            args.events_only,
            args.campaigns_only,
            args.reports_only
        ])

        if sync_all or args.campaigns_only:
            logger.info("üìß Synchronisation des campagnes...")
            api_key = config['brevo']['api_key']
            campaigns = fetch_all_campaigns(api_key)
            if campaigns:
                retrieved_at = datetime.now()
                transformed = [transform_campaign(c, retrieved_at) for c in campaigns]
                upload_campaigns(transformed, config)
                logger.info(f"‚úÖ {len(transformed)} campagnes synchronis√©es")

        if sync_all or args.events_only:
            sync_historical_events(config, start_date, end_date)

        if sync_all or args.reports_only:
            logger.info("\nüìä Synchronisation des rapports SMTP...")
            api_key = config['brevo']['api_key']
            reports = fetch_smtp_report(api_key, start_date, end_date)
            if reports:
                retrieved_at = datetime.now()
                transformed = [transform_report(r, retrieved_at) for r in reports]
                upload_smtp_reports(transformed, config)
                logger.info(f"‚úÖ {len(transformed)} rapports synchronis√©s")

        logger.info("\n‚úÖ SYNCHRONISATION HISTORIQUE TERMIN√âE AVEC SUCC√àS")

    except Exception as e:
        logger.error(f"\n‚ùå ERREUR: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
